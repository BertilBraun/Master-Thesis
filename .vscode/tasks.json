{
    // See https://go.microsoft.com/fwlink/?LinkId=733558
    // for the documentation about the tasks.json format
    "version": "2.0.0",
    "tasks": [
        {
            "label": "Query Example",
            "type": "shell",
            "command": "python -m src.scripts.extract_for_author \"${input:author}\"",
            "problemMatcher": []
        },
        {
            "label": "Generate References",
            "type": "shell",
            "command": "python -m src.scripts.populate_rag_examples ${input:task} ${input:number}",
            "problemMatcher": []
        },
        {
            "label": "Start LocalAI",
            "type": "shell",
            "command": "docker run -p 8080:8080 --name local-ai -ti localai/localai:latest-aio-cpu",
            "problemMatcher": []
        },
        {
            "label": "Run Evaluation analysis",
            "type": "shell",
            "command": "python -m src.scripts.expert_evaluation_analysis",
            "problemMatcher": []
        },
        {
            "label": "Plot GPU Usage",
            "type": "shell",
            "command": "python -m src.finetuning.util.plot_gpu_usage",
            "problemMatcher": []
        },
        {
            "label": "Evaluate after finetuning",
            "type": "shell",
            "command": "python -m src.finetuning.evaluate_model_after_finetuning mlpc",
            "problemMatcher": []
        },
        {
            "label": "PE: Evaluation",
            "type": "shell",
            "command": "python -m src.paper_evaluation_extension.evaluation_elo_and_consistency",
            "problemMatcher": []
        },
        {
            "label": "PE: Evaluation Sort",
            "type": "shell",
            "command": "python -m src.paper_evaluation_extension.evaluation_elo_and_consistency_sort",
            "problemMatcher": []
        }
    ],
    "inputs": [
        {
            "id": "author",
            "type": "promptString",
            "description": "Enter the author to run extraction for",
            "default": "Peter Sanders"
        },
        {
            "id": "abstract",
            "type": "promptString",
            "description": "Enter the abstract to run",
            "default": "Online job ads serve as a valuable source of information for skill requirements, playing a crucial role in labor market analysis and e-recruitment processes. Since such ads are typically formatted in free text, natural language processing (NLP) technologies are required to automatically process them. We specifically focus on the task of detecting skills (mentioned literally, or implicitly described) and linking them to a large skill ontology, making it a challenging case of extreme multi-label classification (XMLC). Given that there is no sizable labeled (training) dataset are available for this specific XMLC task, we propose techniques to leverage general Large Language Models (LLMs). We describe a cost-effective approach to generate an accurate, fully synthetic labeled dataset for skill extraction, and present a contrastive learning strategy that proves effective in the task. Our results across three skill extraction benchmarks show a consistent increase of between 15 to 25 percentage points in R-Precision@5 compared to previously published results that relied solely on distant supervision through literal matches."
        },
        {
            "id": "number",
            "type": "promptString",
            "description": "Enter the number of references to generate",
            "default": "2"
        },
        {
            "id": "task",
            "type": "pickString",
            "description": "Select the task to run",
            "options": [
                "gen_example",
                "gen_combination",
                "gen_ranking"
            ],
            "default": "gen_example"
        }
    ]
}